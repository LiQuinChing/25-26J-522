{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAZQHKVmHyT/uoC4w4NgP1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LiQuinChing/25-26J-522/blob/Detection-of-Arrhythmia-vihara/LoadmodelARRNSR2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfzWWUedv3CK",
        "outputId": "f194ed81-94b8-4cee-b68e-185e4699da63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Hybrid 2D-CNN + LSTM (Leak-proof patient split) for ARR vs NSR\n",
        "# - Uses your folder structure: class_dir / recording_folder / 0.png..9.png\n",
        "# - Groups by patient ID so \"SecondLead\" stays in same split\n",
        "# - Selects 30 patients from ARR and 30 from NSR (if available)\n",
        "# - Splits 70/15/15 by PATIENT (no leakage)\n",
        "# - Lightweight CNN->GAP->LSTM model to reduce overfitting\n",
        "# - Prints model summary\n",
        "# - Confusion matrix + classification report (on TEST set by default)\n",
        "# ============================================================\n",
        "\n",
        "import os, re, random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "p3gozFR5wPX2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 0) Reproducibility\n",
        "# -------------------------\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n"
      ],
      "metadata": {
        "id": "uqw9p3WowQZz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 1) Paths\n",
        "# -------------------------\n",
        "base_dir = \"/content/drive/MyDrive/ECG_Images/ECG_matlab_images\"\n",
        "arr_base = os.path.join(base_dir, \"MATLAB_arrhythmia\")\n",
        "nsr_base = os.path.join(base_dir, \"MATLAB_normal\")"
      ],
      "metadata": {
        "id": "_Mt-ixnuwTu2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 2) Constants\n",
        "# -------------------------\n",
        "IMG_H, IMG_W = 227, 227\n",
        "SEQ_LEN = 10\n",
        "NUM_CLASSES = 2\n",
        "IMG_EXTS = (\".png\", \".jpg\", \".jpeg\")"
      ],
      "metadata": {
        "id": "Po94Ru_uw47b"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 3) Helpers\n",
        "# -------------------------\n",
        "def is_image_file(p: str) -> bool:\n",
        "    return p.lower().endswith(IMG_EXTS)\n",
        "\n",
        "def extract_patient_id(folder_name: str, class_type: str) -> str:\n",
        "    \"\"\"\n",
        "    Extract patient/record ID based on your folder naming conventions.\n",
        "\n",
        "    ARR example: 100_MLII_segments -> \"100\"\n",
        "    NSR examples: TenSegof19090 -> \"19090\"\n",
        "                  TenSegof19090SecondLead -> \"19090\"\n",
        "\n",
        "    Returns a string patient ID.\n",
        "    \"\"\"\n",
        "    name = folder_name.lower()\n",
        "\n",
        "    if class_type == \"arr\":\n",
        "        # take leading digits before underscore if present; fallback to first digits anywhere\n",
        "        m = re.match(r\"(\\d+)\", folder_name)\n",
        "        if m:\n",
        "            return m.group(1)\n",
        "        nums = re.findall(r\"\\d+\", folder_name)\n",
        "        return nums[0] if nums else folder_name\n",
        "\n",
        "    # nsr\n",
        "    # capture digits after \"tensegof\"\n",
        "    m = re.search(r\"tensegof(\\d+)\", name)\n",
        "    if m:\n",
        "        return m.group(1)\n",
        "    # fallback: first number in name\n",
        "    nums = re.findall(r\"\\d+\", folder_name)\n",
        "    return nums[0] if nums else folder_name\n",
        "\n",
        "def load_sequence_from_folder(folder_path: str, seq_len: int = 10) -> list:\n",
        "    \"\"\"\n",
        "    Loads a sequence as a LIST OF IMAGE PATHS (length seq_len) from one recording folder.\n",
        "    Assumes file names are 0.png..9.png (or at least numeric stem).\n",
        "    \"\"\"\n",
        "    imgs = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if is_image_file(f)]\n",
        "    if len(imgs) < seq_len:\n",
        "        return None\n",
        "\n",
        "    # Sort by numeric filename: \"0.png\" -> 0, \"9.png\" -> 9\n",
        "    def num_key(p):\n",
        "        stem = os.path.splitext(os.path.basename(p))[0]\n",
        "        m = re.findall(r\"\\d+\", stem)\n",
        "        return int(m[0]) if m else 10**9\n",
        "\n",
        "    imgs.sort(key=num_key)\n",
        "    seq = imgs[:seq_len]\n",
        "    return seq if len(seq) == seq_len else None\n",
        "\n",
        "def build_patient_groups(class_root: str, class_type: str, seq_len: int = 10):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      patient_to_seqs: dict patient_id -> list of sequences (each sequence = list of image paths)\n",
        "    Note: If a patient has 2 leads saved as 2 folders, we will store TWO sequences under same patient.\n",
        "    \"\"\"\n",
        "    patient_to_seqs = {}\n",
        "    subdirs = [d for d in os.listdir(class_root) if os.path.isdir(os.path.join(class_root, d))]\n",
        "    subdirs.sort()\n",
        "\n",
        "    for d in subdirs:\n",
        "        pid = extract_patient_id(d, class_type)\n",
        "        folder_path = os.path.join(class_root, d)\n",
        "        seq = load_sequence_from_folder(folder_path, seq_len=seq_len)\n",
        "        if seq is None:\n",
        "            continue\n",
        "        patient_to_seqs.setdefault(pid, []).append(seq)\n",
        "\n",
        "    return patient_to_seqs\n",
        "\n",
        "def choose_n_patients(patient_to_seqs: dict, n_patients: int):\n",
        "    \"\"\"\n",
        "    Randomly choose n_patients (patient IDs). Returns reduced dict.\n",
        "    \"\"\"\n",
        "    pids = list(patient_to_seqs.keys())\n",
        "    random.shuffle(pids)\n",
        "    chosen = pids[:min(n_patients, len(pids))]\n",
        "    return {pid: patient_to_seqs[pid] for pid in chosen}\n",
        "\n",
        "def split_patients(patient_ids: list, train_ratio=0.70, val_ratio=0.15, test_ratio=0.15):\n",
        "    \"\"\"\n",
        "    Split patient IDs (not sequences!) into train/val/test.\n",
        "    \"\"\"\n",
        "    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6\n",
        "\n",
        "    patient_ids = list(patient_ids)\n",
        "    random.shuffle(patient_ids)\n",
        "\n",
        "    n = len(patient_ids)\n",
        "    n_train = int(train_ratio * n)\n",
        "    n_val = int(val_ratio * n)\n",
        "\n",
        "    train_ids = patient_ids[:n_train]\n",
        "    val_ids = patient_ids[n_train:n_train + n_val]\n",
        "    test_ids = patient_ids[n_train + n_val:]\n",
        "\n",
        "    return train_ids, val_ids, test_ids\n",
        "\n",
        "def flatten_patient_dict(patient_to_seqs: dict, patient_id_list: list, label: int):\n",
        "    \"\"\"\n",
        "    From patient_to_seqs and a list of patient IDs, return:\n",
        "      X: list of sequences (each seq = list of 10 paths)\n",
        "      y: list of int labels aligned to X\n",
        "    Important: If a patient has 2 sequences (two leads), both go to same split.\n",
        "    \"\"\"\n",
        "    X, y = [], []\n",
        "    for pid in patient_id_list:\n",
        "        seqs = patient_to_seqs.get(pid, [])\n",
        "        for seq in seqs:\n",
        "            X.append(seq)\n",
        "            y.append(label)\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "_UM7BfV6wzHb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 4) Build patient groups (leak-proof)\n",
        "# -------------------------\n",
        "arr_patient_to_seqs = build_patient_groups(arr_base, \"arr\", seq_len=SEQ_LEN)\n",
        "nsr_patient_to_seqs = build_patient_groups(nsr_base, \"nsr\", seq_len=SEQ_LEN)\n",
        "\n",
        "print(\"ARR patients found:\", len(arr_patient_to_seqs))\n",
        "print(\"NSR patients found:\", len(nsr_patient_to_seqs))\n",
        "\n",
        "# Select 30 patients each (as you requested)\n",
        "N_PER_CLASS_PATIENTS = 30\n",
        "arr_patient_to_seqs = choose_n_patients(arr_patient_to_seqs, N_PER_CLASS_PATIENTS)\n",
        "nsr_patient_to_seqs = choose_n_patients(nsr_patient_to_seqs, N_PER_CLASS_PATIENTS)\n",
        "\n",
        "print(\"ARR patients used:\", len(arr_patient_to_seqs))\n",
        "print(\"NSR patients used:\", len(nsr_patient_to_seqs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1rSgsShw961",
        "outputId": "d5987f6c-ae3a-4eca-85d8-4f9cef249938"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ARR patients found: 48\n",
            "NSR patients found: 18\n",
            "ARR patients used: 30\n",
            "NSR patients used: 18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 5) Split by patient IDs (70/15/15) - NO LEAKAGE\n",
        "# -------------------------\n",
        "arr_pids = list(arr_patient_to_seqs.keys())\n",
        "nsr_pids = list(nsr_patient_to_seqs.keys())\n",
        "\n",
        "arr_train_ids, arr_val_ids, arr_test_ids = split_patients(arr_pids, 0.70, 0.15, 0.15)\n",
        "nsr_train_ids, nsr_val_ids, nsr_test_ids = split_patients(nsr_pids, 0.70, 0.15, 0.15)\n",
        "\n",
        "X_train_arr, y_train_arr = flatten_patient_dict(arr_patient_to_seqs, arr_train_ids, label=1)\n",
        "X_val_arr,   y_val_arr   = flatten_patient_dict(arr_patient_to_seqs, arr_val_ids,   label=1)\n",
        "X_test_arr,  y_test_arr  = flatten_patient_dict(arr_patient_to_seqs, arr_test_ids,  label=1)\n",
        "\n",
        "X_train_nsr, y_train_nsr = flatten_patient_dict(nsr_patient_to_seqs, nsr_train_ids, label=0)\n",
        "X_val_nsr,   y_val_nsr   = flatten_patient_dict(nsr_patient_to_seqs, nsr_val_ids,   label=0)\n",
        "X_test_nsr,  y_test_nsr  = flatten_patient_dict(nsr_patient_to_seqs, nsr_test_ids,  label=0)\n",
        "\n",
        "X_train = X_train_arr + X_train_nsr\n",
        "y_train = y_train_arr + y_train_nsr\n",
        "X_val   = X_val_arr   + X_val_nsr\n",
        "y_val   = y_val_arr   + y_val_nsr\n",
        "X_test  = X_test_arr  + X_test_nsr\n",
        "y_test  = y_test_arr  + y_test_nsr\n",
        "\n",
        "# Shuffle within each split\n",
        "def shuffle_split(X, y):\n",
        "    combined = list(zip(X, y))\n",
        "    random.shuffle(combined)\n",
        "    X, y = zip(*combined) if combined else ([], [])\n",
        "    return list(X), np.array(list(y), dtype=np.int32)\n",
        "\n",
        "X_train, y_train = shuffle_split(X_train, y_train)\n",
        "X_val,   y_val   = shuffle_split(X_val, y_val)\n",
        "X_test,  y_test  = shuffle_split(X_test, y_test)\n",
        "\n",
        "print(\"\\nSequences (samples) after split:\")\n",
        "print(\"Train sequences:\", len(X_train))\n",
        "print(\"Val sequences:\",   len(X_val))\n",
        "print(\"Test sequences:\",  len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUUwWVSBywsC",
        "outputId": "d1eef4e3-3063-4ec8-aeb7-18604162e029"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sequences (samples) after split:\n",
            "Train sequences: 45\n",
            "Val sequences: 8\n",
            "Test sequences: 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 6) tf.data pipeline (sequence -> tensor [T,H,W,3])\n",
        "# -------------------------\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "def decode_and_resize(img_bytes):\n",
        "    img = tf.image.decode_image(img_bytes, channels=3, expand_animations=False)\n",
        "    img = tf.image.resize(img, (IMG_H, IMG_W))\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "    return img\n",
        "\n",
        "def load_sequence(seq_paths, label):\n",
        "    imgs = tf.map_fn(\n",
        "        lambda p: decode_and_resize(tf.io.read_file(p)),\n",
        "        seq_paths,\n",
        "        fn_output_signature=tf.float32\n",
        "    )\n",
        "    # one-hot for categorical_crossentropy\n",
        "    label_onehot = tf.one_hot(label, depth=NUM_CLASSES)\n",
        "    return imgs, label_onehot\n",
        "\n",
        "def make_dataset(X_seqs, y_labels, batch_size=8, shuffle=True):\n",
        "    X_arr = tf.constant(X_seqs)  # shape [N, T]\n",
        "    y_arr = tf.constant(y_labels)\n",
        "    ds = tf.data.Dataset.from_tensor_slices((X_arr, y_arr))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=len(X_seqs), reshuffle_each_iteration=True, seed=SEED)\n",
        "    ds = ds.map(load_sequence, num_parallel_calls=AUTOTUNE)\n",
        "    ds = ds.batch(batch_size).prefetch(AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "train_ds = make_dataset(X_train, y_train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_ds   = make_dataset(X_val,   y_val,   batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_ds  = make_dataset(X_test,  y_test,  batch_size=BATCH_SIZE, shuffle=False)\n"
      ],
      "metadata": {
        "id": "vDeeqSXjy1iU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 7) Lightweight Hybrid Model (CNN -> GAP -> LSTM)\n",
        "# -------------------------\n",
        "def build_small_hybrid(seq_len=10, img_h=227, img_w=227, channels=3,\n",
        "                       lstm_units=32, dropout=0.5, l2=1e-4):\n",
        "    inp = tf.keras.Input(shape=(seq_len, img_h, img_w, channels), name=\"sequence_input\")\n",
        "\n",
        "    x = tf.keras.layers.TimeDistributed(\n",
        "        tf.keras.layers.Conv2D(32, (3,3), padding=\"same\",\n",
        "                               kernel_regularizer=tf.keras.regularizers.l2(l2)),\n",
        "        name=\"td_conv32\"\n",
        "    )(inp)\n",
        "    x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization(), name=\"td_bn1\")(x)\n",
        "    x = tf.keras.layers.TimeDistributed(tf.keras.layers.ReLU(), name=\"td_relu1\")(x)\n",
        "    x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPooling2D((2,2)), name=\"td_pool1\")(x)\n",
        "\n",
        "    x = tf.keras.layers.TimeDistributed(\n",
        "        tf.keras.layers.Conv2D(64, (3,3), padding=\"same\",\n",
        "                               kernel_regularizer=tf.keras.regularizers.l2(l2)),\n",
        "        name=\"td_conv64\"\n",
        "    )(x)\n",
        "    x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization(), name=\"td_bn2\")(x)\n",
        "    x = tf.keras.layers.TimeDistributed(tf.keras.layers.ReLU(), name=\"td_relu2\")(x)\n",
        "    x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPooling2D((2,2)), name=\"td_pool2\")(x)\n",
        "\n",
        "    x = tf.keras.layers.TimeDistributed(\n",
        "        tf.keras.layers.Conv2D(128, (3,3), padding=\"same\",\n",
        "                               kernel_regularizer=tf.keras.regularizers.l2(l2)),\n",
        "        name=\"td_conv128\"\n",
        "    )(x)\n",
        "    x = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization(), name=\"td_bn3\")(x)\n",
        "    x = tf.keras.layers.TimeDistributed(tf.keras.layers.ReLU(), name=\"td_relu3\")(x)\n",
        "\n",
        "    # Key overfitting reducer: GAP instead of Flatten\n",
        "    x = tf.keras.layers.TimeDistributed(tf.keras.layers.GlobalAveragePooling2D(),\n",
        "                                        name=\"td_gap\")(x)\n",
        "\n",
        "    x = tf.keras.layers.LSTM(lstm_units,\n",
        "                             dropout=0.2,\n",
        "                             recurrent_dropout=0.2,\n",
        "                             name=\"lstm\")(x)\n",
        "\n",
        "    x = tf.keras.layers.Dense(128, activation=\"relu\",\n",
        "                              kernel_regularizer=tf.keras.regularizers.l2(l2),\n",
        "                              name=\"dense_128\")(x)\n",
        "    x = tf.keras.layers.Dropout(dropout, name=\"dropout\")(x)\n",
        "\n",
        "    out = tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\", name=\"softmax_out\")(x)\n",
        "    return tf.keras.Model(inp, out, name=\"Small_2DCNN_LSTM_ARR_NSR\")\n",
        "\n",
        "model = build_small_hybrid(seq_len=SEQ_LEN, img_h=IMG_H, img_w=IMG_W, channels=3,\n",
        "                           lstm_units=32, dropout=0.5, l2=1e-4)\n",
        "\n",
        "# Model summary (as requested)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 871
        },
        "id": "MpuuHJY7y5gv",
        "outputId": "39d0cc95-3a9b-4bf4-d53a-84d1c1dd7deb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"Small_2DCNN_LSTM_ARR_NSR\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Small_2DCNN_LSTM_ARR_NSR\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ sequence_input (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m227\u001b[0m, \u001b[38;5;34m227\u001b[0m,   │             \u001b[38;5;34m0\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m3\u001b[0m)                     │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ td_conv32 (\u001b[38;5;33mTimeDistributed\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m227\u001b[0m, \u001b[38;5;34m227\u001b[0m,   │           \u001b[38;5;34m896\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m32\u001b[0m)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ td_bn1 (\u001b[38;5;33mTimeDistributed\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m227\u001b[0m, \u001b[38;5;34m227\u001b[0m,   │           \u001b[38;5;34m128\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m32\u001b[0m)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ td_relu1 (\u001b[38;5;33mTimeDistributed\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m227\u001b[0m, \u001b[38;5;34m227\u001b[0m,   │             \u001b[38;5;34m0\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m32\u001b[0m)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ td_pool1 (\u001b[38;5;33mTimeDistributed\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m113\u001b[0m, \u001b[38;5;34m113\u001b[0m,   │             \u001b[38;5;34m0\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m32\u001b[0m)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ td_conv64 (\u001b[38;5;33mTimeDistributed\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m113\u001b[0m, \u001b[38;5;34m113\u001b[0m,   │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m64\u001b[0m)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ td_bn2 (\u001b[38;5;33mTimeDistributed\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m113\u001b[0m, \u001b[38;5;34m113\u001b[0m,   │           \u001b[38;5;34m256\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m64\u001b[0m)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ td_relu2 (\u001b[38;5;33mTimeDistributed\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m113\u001b[0m, \u001b[38;5;34m113\u001b[0m,   │             \u001b[38;5;34m0\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m64\u001b[0m)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ td_pool2 (\u001b[38;5;33mTimeDistributed\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m) │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ td_conv128 (\u001b[38;5;33mTimeDistributed\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,     │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m128\u001b[0m)                   │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ td_bn3 (\u001b[38;5;33mTimeDistributed\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,     │           \u001b[38;5;34m512\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m128\u001b[0m)                   │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ td_relu3 (\u001b[38;5;33mTimeDistributed\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m,     │             \u001b[38;5;34m0\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m128\u001b[0m)                   │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ td_gap (\u001b[38;5;33mTimeDistributed\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m20,608\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_128 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m4,224\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ softmax_out (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m258\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ sequence_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">227</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">227</span>,   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                     │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ td_conv32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">227</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">227</span>,   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ td_bn1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">227</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">227</span>,   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ td_relu1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">227</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">227</span>,   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ td_pool1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">113</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">113</span>,   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ td_conv64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">113</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">113</span>,   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ td_bn2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">113</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">113</span>,   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ td_relu2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">113</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">113</span>,   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                    │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ td_pool2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>) │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ td_conv128 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ td_bn3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ td_relu3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>,     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ td_gap (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,608</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_128 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ softmax_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m119,234\u001b[0m (465.76 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">119,234</span> (465.76 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m118,786\u001b[0m (464.01 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,786</span> (464.01 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 8) Compile + Train\n",
        "# -------------------------\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.05)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss=loss_fn,\n",
        "    metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"auc\")]\n",
        ")\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=8,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\",\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=10,\n",
        "    callbacks=[early_stop, reduce_lr],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5isqzOYay9Ul",
        "outputId": "e0dbbedc-fb7e-4f81-bcb9-2082cf3e3f5c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 53s/step - accuracy: 0.5329 - auc: 0.6119 - loss: 0.6929 - val_accuracy: 0.5000 - val_auc: 0.4375 - val_loss: 0.7200 - learning_rate: 1.0000e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 47s/step - accuracy: 0.6096 - auc: 0.5307 - loss: 0.7164 - val_accuracy: 0.5000 - val_auc: 0.6875 - val_loss: 0.7179 - learning_rate: 1.0000e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 47s/step - accuracy: 0.7050 - auc: 0.7675 - loss: 0.6265 - val_accuracy: 0.5000 - val_auc: 0.7344 - val_loss: 0.7003 - learning_rate: 1.0000e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 47s/step - accuracy: 0.8113 - auc: 0.8961 - loss: 0.5800 - val_accuracy: 0.5000 - val_auc: 0.7500 - val_loss: 0.6802 - learning_rate: 1.0000e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 45s/step - accuracy: 0.7671 - auc: 0.8334 - loss: 0.5925 - val_accuracy: 0.8750 - val_auc: 0.9922 - val_loss: 0.6542 - learning_rate: 1.0000e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 44s/step - accuracy: 0.7735 - auc: 0.9385 - loss: 0.5424 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 0.6185 - learning_rate: 1.0000e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 46s/step - accuracy: 0.9500 - auc: 0.9800 - loss: 0.5251 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 0.5698 - learning_rate: 1.0000e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 47s/step - accuracy: 0.8805 - auc: 0.9713 - loss: 0.5047 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 0.5147 - learning_rate: 1.0000e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 44s/step - accuracy: 0.9010 - auc: 0.8986 - loss: 0.5603 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 0.4541 - learning_rate: 1.0000e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 46s/step - accuracy: 0.8790 - auc: 0.9726 - loss: 0.4624 - val_accuracy: 1.0000 - val_auc: 1.0000 - val_loss: 0.4118 - learning_rate: 1.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# 9) Evaluate + Confusion Matrix (TEST set is best practice)\n",
        "# -------------------------\n",
        "print(\"\\n=== TEST EVALUATION ===\")\n",
        "test_results = model.evaluate(test_ds, verbose=1)\n",
        "print(dict(zip(model.metrics_names, test_results)))\n",
        "\n",
        "# Predict on test set (recording-level: 1 prediction per sequence/recording-folder)\n",
        "y_prob = model.predict(test_ds)\n",
        "y_pred = np.argmax(y_prob, axis=1)\n",
        "\n",
        "# True labels (convert one-hot labels from y_test which we stored as ints already)\n",
        "y_true = y_test\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(\"\\nConfusion Matrix (TEST) [rows=true, cols=pred]:\")\n",
        "print(cm)\n",
        "\n",
        "print(\"\\nClassification Report (TEST):\")\n",
        "print(classification_report(y_true, y_pred, target_names=[\"NSR\", \"ARR\"]))\n",
        "\n",
        "# If you ALSO want confusion matrix for VAL (optional)\n",
        "print(\"\\n=== VAL CONFUSION MATRIX (optional check) ===\")\n",
        "y_prob_val = model.predict(val_ds)\n",
        "y_pred_val = np.argmax(y_prob_val, axis=1)\n",
        "cm_val = confusion_matrix(y_val, y_pred_val)\n",
        "print(\"Confusion Matrix (VAL) [rows=true, cols=pred]:\")\n",
        "print(cm_val)\n",
        "print(\"\\nClassification Report (VAL):\")\n",
        "print(classification_report(y_val, y_pred_val, target_names=[\"NSR\", \"ARR\"]))"
      ],
      "metadata": {
        "id": "kGg-c-6nzCne",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b6dab65-e183-4b85-eda7-cfcefd722738"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== TEST EVALUATION ===\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.4008\n",
            "{'loss': 0.4087607264518738, 'compile_metrics': 1.0}\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5s/step\n",
            "\n",
            "Confusion Matrix (TEST) [rows=true, cols=pred]:\n",
            "[[8 0]\n",
            " [0 5]]\n",
            "\n",
            "Classification Report (TEST):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         NSR       1.00      1.00      1.00         8\n",
            "         ARR       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           1.00        13\n",
            "   macro avg       1.00      1.00      1.00        13\n",
            "weighted avg       1.00      1.00      1.00        13\n",
            "\n",
            "\n",
            "=== VAL CONFUSION MATRIX (optional check) ===\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "Confusion Matrix (VAL) [rows=true, cols=pred]:\n",
            "[[4 0]\n",
            " [0 4]]\n",
            "\n",
            "Classification Report (VAL):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         NSR       1.00      1.00      1.00         4\n",
            "         ARR       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           1.00         8\n",
            "   macro avg       1.00      1.00      1.00         8\n",
            "weighted avg       1.00      1.00      1.00         8\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 10) Final Evaluation (Test set)\n",
        "# =========================\n",
        "results = model.evaluate(test_ds, verbose=1)\n",
        "print(\"Test results:\", dict(zip(model.metrics_names, results)))\n",
        "\n",
        "# =========================\n",
        "# 11) Save the trained model\n",
        "# =========================\n",
        "MODEL_SAVE_PATH = \"/content/drive/MyDrive/ECG_Images/small_2dcnn_lstm_arr_nsrAgain.keras\"\n",
        "\n",
        "model.save(MODEL_SAVE_PATH)\n",
        "print(f\"Model saved to: {MODEL_SAVE_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugXzeBrvI6kd",
        "outputId": "a0cf6e10-4830-4bf5-dbde-c5777f26756e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.4008\n",
            "Test results: {'loss': 0.4087607264518738, 'compile_metrics': 1.0}\n",
            "Model saved to: /content/drive/MyDrive/ECG_Images/small_2dcnn_lstm_arr_nsrAgain.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# A) TEST RESULTS + CONFUSION MATRIX (for your recent model)\n",
        "#    - Uses the split test_ds you already created\n",
        "#    - Gives accuracy, AUC, loss\n",
        "#    - Confusion matrix + classification report\n",
        "#    - Also prints per-class accuracy\n",
        "# ============================================================\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "print(\"\\n=== TEST EVALUATION (unseen split) ===\")\n",
        "test_results = model.evaluate(test_ds, verbose=1)\n",
        "print(\"Test results:\", dict(zip(model.metrics_names, test_results)))\n",
        "\n",
        "# Predict probabilities on the unseen test split\n",
        "y_prob_test = model.predict(test_ds, verbose=1)\n",
        "y_pred_test = np.argmax(y_prob_test, axis=1)\n",
        "\n",
        "# True labels are the integer labels you created during split\n",
        "# (y_test is your numpy array with 0=NSR, 1=ARR)\n",
        "y_true_test = y_test\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_true_test, y_pred_test)\n",
        "print(\"\\nConfusion Matrix (TEST) [rows=true, cols=pred] (0=NSR, 1=ARR):\")\n",
        "print(cm)\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report (TEST):\")\n",
        "print(classification_report(y_true_test, y_pred_test, target_names=[\"NSR\", \"ARR\"]))\n",
        "\n",
        "# Overall accuracy (sanity check)\n",
        "acc = accuracy_score(y_true_test, y_pred_test)\n",
        "print(\"Overall Test Accuracy:\", acc)\n",
        "\n",
        "# Per-class accuracy\n",
        "# cm:\n",
        "# [[TN FP],\n",
        "#  [FN TP]]\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "nsr_acc = tn / (tn + fp) if (tn + fp) else 0.0\n",
        "arr_acc = tp / (tp + fn) if (tp + fn) else 0.0\n",
        "print(f\"Per-class accuracy: NSR={nsr_acc:.4f}, ARR={arr_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "NBR-6QtIfhfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54f60da3-ebc7-4117-bf27-cad45732215a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== TEST EVALUATION (unseen split) ===\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.4008\n",
            "Test results: {'loss': 0.4087607264518738, 'compile_metrics': 1.0}\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3s/step\n",
            "\n",
            "Confusion Matrix (TEST) [rows=true, cols=pred] (0=NSR, 1=ARR):\n",
            "[[8 0]\n",
            " [0 5]]\n",
            "\n",
            "Classification Report (TEST):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         NSR       1.00      1.00      1.00         8\n",
            "         ARR       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           1.00        13\n",
            "   macro avg       1.00      1.00      1.00        13\n",
            "weighted avg       1.00      1.00      1.00        13\n",
            "\n",
            "Overall Test Accuracy: 1.0\n",
            "Per-class accuracy: NSR=1.0000, ARR=1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 11) Save model + splits + config\n",
        "# =========================\n",
        "MODEL_SAVE_PATH = \"/content/drive/MyDrive/ECG_Images/small_2dcnn_lstm_arr_nsrAgain.keras\"\n",
        "SPLIT_SAVE_PATH = \"/content/drive/MyDrive/ECG_Images/small_2dcnn_lstm_arr_nsrAgain_splits.json\"\n"
      ],
      "metadata": {
        "id": "Kdxy806UWQ21"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "def save_splits_and_config(\n",
        "    split_save_path: str,\n",
        "    X_train, y_train,\n",
        "    X_val, y_val,\n",
        "    X_test, y_test,\n",
        "    config: dict\n",
        "):\n",
        "    payload = {\n",
        "        \"saved_at\": datetime.now().isoformat(),\n",
        "        \"config\": config,\n",
        "\n",
        "        # IMPORTANT: store file-path sequences and integer labels\n",
        "        \"train\": {\"X\": X_train, \"y\": [int(x) for x in list(y_train)]},\n",
        "        \"val\":   {\"X\": X_val,   \"y\": [int(x) for x in list(y_val)]},\n",
        "        \"test\":  {\"X\": X_test,  \"y\": [int(x) for x in list(y_test)]},\n",
        "    }\n",
        "\n",
        "    os.makedirs(os.path.dirname(split_save_path), exist_ok=True)\n",
        "    with open(split_save_path, \"w\") as f:\n",
        "        json.dump(payload, f)\n",
        "\n",
        "    print(\"Saved splits+config to:\", split_save_path)\n",
        "\n",
        "\n",
        "# Save your preprocessing + training-time config that must be consistent later\n",
        "CONFIG = {\n",
        "    \"SEED\": SEED,\n",
        "    \"IMG_H\": IMG_H,\n",
        "    \"IMG_W\": IMG_W,\n",
        "    \"SEQ_LEN\": SEQ_LEN,\n",
        "    \"NUM_CLASSES\": NUM_CLASSES,\n",
        "    \"NORMALIZE_DIV\": 255.0,\n",
        "    \"LABEL_MAP\": {\"0\": \"NSR\", \"1\": \"ARR\"},\n",
        "    \"IMG_EXTS\": list(IMG_EXTS),\n",
        "    \"base_dir\": base_dir,\n",
        "    \"arr_base\": arr_base,\n",
        "    \"nsr_base\": nsr_base,\n",
        "    \"N_PER_CLASS_PATIENTS\": N_PER_CLASS_PATIENTS,\n",
        "    \"split_ratio\": {\"train\": 0.70, \"val\": 0.15, \"test\": 0.15}\n",
        "}\n",
        "\n",
        "save_splits_and_config(\n",
        "    SPLIT_SAVE_PATH,\n",
        "    X_train, y_train,\n",
        "    X_val, y_val,\n",
        "    X_test, y_test,\n",
        "    CONFIG\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hU0_yioLWUEi",
        "outputId": "4c2a8fb4-65d2-4ec9-94fa-9903225bdf8a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved splits+config to: /content/drive/MyDrive/ECG_Images/small_2dcnn_lstm_arr_nsrAgain_splits.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 10) Final Evaluation (TEST set) + Confusion Matrix\n",
        "# =========================\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "print(\"\\n=== TEST EVALUATION (unseen split) ===\")\n",
        "test_results = model.evaluate(test_ds, verbose=1)\n",
        "print(\"Test results:\", dict(zip(model.metrics_names, test_results)))\n",
        "\n",
        "# Predict on test set\n",
        "y_prob_test = model.predict(test_ds, verbose=1)\n",
        "y_pred_test = np.argmax(y_prob_test, axis=1)\n",
        "\n",
        "# True labels (integer labels you created)\n",
        "y_true_test = y_test\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_true_test, y_pred_test)\n",
        "print(\"\\nConfusion Matrix (TEST) [rows=true, cols=pred] (0=NSR, 1=ARR):\")\n",
        "print(cm)\n",
        "\n",
        "print(\"\\nClassification Report (TEST):\")\n",
        "print(classification_report(y_true_test, y_pred_test, target_names=[\"NSR\", \"ARR\"]))\n",
        "\n",
        "# Overall accuracy\n",
        "acc = accuracy_score(y_true_test, y_pred_test)\n",
        "print(\"Overall Test Accuracy:\", acc)\n",
        "\n",
        "# Per-class accuracy\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "nsr_acc = tn / (tn + fp) if (tn + fp) else 0.0\n",
        "arr_acc = tp / (tp + fn) if (tp + fn) else 0.0\n",
        "print(f\"Per-class accuracy: NSR={nsr_acc:.4f}, ARR={arr_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkoheuShWehu",
        "outputId": "17a16b05-3849-431a-c008-e472f636d9d2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== TEST EVALUATION (unseen split) ===\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.4008\n",
            "Test results: {'loss': 0.4087607264518738, 'compile_metrics': 1.0}\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4s/step\n",
            "\n",
            "Confusion Matrix (TEST) [rows=true, cols=pred] (0=NSR, 1=ARR):\n",
            "[[8 0]\n",
            " [0 5]]\n",
            "\n",
            "Classification Report (TEST):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         NSR       1.00      1.00      1.00         8\n",
            "         ARR       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           1.00        13\n",
            "   macro avg       1.00      1.00      1.00        13\n",
            "weighted avg       1.00      1.00      1.00        13\n",
            "\n",
            "Overall Test Accuracy: 1.0\n",
            "Per-class accuracy: NSR=1.0000, ARR=1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# If you already have:\n",
        "# y_true_test = y_test\n",
        "# y_pred_test = np.argmax(model.predict(test_ds), axis=1)\n",
        "# then keep those and only run from here.\n",
        "\n",
        "cm = confusion_matrix(y_true_test, y_pred_test)\n",
        "\n",
        "class_names = [\"NSR\", \"ARR\"]  # 0=NSR, 1=ARR\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.imshow(cm, interpolation=\"nearest\")\n",
        "plt.title(\"Confusion Matrix (Test Set)\")\n",
        "plt.colorbar()\n",
        "\n",
        "tick_marks = np.arange(len(class_names))\n",
        "plt.xticks(tick_marks, class_names, rotation=0)\n",
        "plt.yticks(tick_marks, class_names)\n",
        "\n",
        "# Write numbers in cells\n",
        "thresh = cm.max() / 2.0\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        plt.text(\n",
        "            j, i, format(cm[i, j], \"d\"),\n",
        "            ha=\"center\", va=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\"\n",
        "        )\n",
        "\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "HsqCetFJW2kM",
        "outputId": "53f0a508-82d3-460e-f084-038ecd57aa0e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 11) Save the trained model\n",
        "# =========================\n",
        "model.save(MODEL_SAVE_PATH)\n",
        "print(f\"Model saved to: {MODEL_SAVE_PATH}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJCKXmfnWgVa",
        "outputId": "bac8fb72-7594-42b0-fc1f-cee0bacccd4b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to: /content/drive/MyDrive/ECG_Images/small_2dcnn_lstm_arr_nsrAgain.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART 2: Later — Load model + load splits + rebuild datasets instantly (NO TRAINING)"
      ],
      "metadata": {
        "id": "a3R9Tk52Wm-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# B) LOAD SAVED MODEL + LOAD SPLITS + REBUILD DATASETS (NO TRAINING)\n",
        "# ============================================================\n",
        "import json\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "MODEL_SAVE_PATH = \"/content/drive/MyDrive/ECG_Images/small_2dcnn_lstm_arr_nsrAgain.keras\"\n",
        "SPLIT_SAVE_PATH = \"/content/drive/MyDrive/ECG_Images/small_2dcnn_lstm_arr_nsrAgain_splits.json\"\n",
        "\n",
        "loaded_model = tf.keras.models.load_model(MODEL_SAVE_PATH)\n",
        "print(\"Loaded model OK.\")\n",
        "\n",
        "with open(SPLIT_SAVE_PATH, \"r\") as f:\n",
        "    payload = json.load(f)\n",
        "\n",
        "cfg = payload[\"config\"]\n",
        "\n",
        "# Restore critical settings\n",
        "SEED = int(cfg[\"SEED\"])\n",
        "IMG_H = int(cfg[\"IMG_H\"])\n",
        "IMG_W = int(cfg[\"IMG_W\"])\n",
        "SEQ_LEN = int(cfg[\"SEQ_LEN\"])\n",
        "NUM_CLASSES = int(cfg[\"NUM_CLASSES\"])\n",
        "label_map = {0: cfg[\"LABEL_MAP\"][\"0\"], 1: cfg[\"LABEL_MAP\"][\"1\"]}\n",
        "\n",
        "# Restore splits\n",
        "X_train = payload[\"train\"][\"X\"]; y_train = np.array(payload[\"train\"][\"y\"], dtype=np.int32)\n",
        "X_val   = payload[\"val\"][\"X\"];   y_val   = np.array(payload[\"val\"][\"y\"], dtype=np.int32)\n",
        "X_test  = payload[\"test\"][\"X\"];  y_test  = np.array(payload[\"test\"][\"y\"], dtype=np.int32)\n",
        "\n",
        "print(\"Loaded split sizes:\",\n",
        "      len(X_train), len(X_val), len(X_test))\n",
        "\n",
        "# Recreate datasets instantly (same functions as training)\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "def decode_and_resize(img_bytes):\n",
        "    img = tf.image.decode_image(img_bytes, channels=3, expand_animations=False)\n",
        "    img = tf.image.resize(img, (IMG_H, IMG_W))\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "    return img\n",
        "\n",
        "def load_sequence(seq_paths, label):\n",
        "    imgs = tf.map_fn(\n",
        "        lambda p: decode_and_resize(tf.io.read_file(p)),\n",
        "        seq_paths,\n",
        "        fn_output_signature=tf.float32\n",
        "    )\n",
        "    label_onehot = tf.one_hot(label, depth=NUM_CLASSES)\n",
        "    return imgs, label_onehot\n",
        "\n",
        "def make_dataset(X_seqs, y_labels, batch_size=8, shuffle=False):\n",
        "    X_arr = tf.constant(X_seqs)   # shape [N, T]\n",
        "    y_arr = tf.constant(y_labels)\n",
        "    ds = tf.data.Dataset.from_tensor_slices((X_arr, y_arr))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size=len(X_seqs), seed=SEED, reshuffle_each_iteration=True)\n",
        "    ds = ds.map(load_sequence, num_parallel_calls=AUTOTUNE)\n",
        "    ds = ds.batch(batch_size).prefetch(AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "train_ds = make_dataset(X_train, y_train, batch_size=BATCH_SIZE, shuffle=False)\n",
        "val_ds   = make_dataset(X_val,   y_val,   batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_ds  = make_dataset(X_test,  y_test,  batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Evaluate without retraining\n",
        "results = loaded_model.evaluate(test_ds, verbose=1)\n",
        "print(\"Test results:\", dict(zip(loaded_model.metrics_names, results)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBqZJaRGWkGD",
        "outputId": "6e912816-ea00-416f-b21a-c00c05d711db"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model OK.\n",
            "Loaded split sizes: 45 8 13\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 1.0000 - auc: 1.0000 - loss: 0.4008\n",
            "Test results: {'loss': 0.4087607264518738, 'compile_metrics': 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# C) LOAD SAVED MODEL + MANUAL UPLOAD (ZIP) + PREDICT\n",
        "# ============================================================\n",
        "import os, zipfile, re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from google.colab import files\n",
        "\n",
        "print(\"\\nUpload a ZIP containing 10 scalogram images (e.g., 0.png..9.png).\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "zip_name = list(uploaded.keys())[0]\n",
        "extract_dir = \"/content/manual_test_recording\"\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_name, \"r\") as z:\n",
        "    z.extractall(extract_dir)\n",
        "\n",
        "# Collect images\n",
        "img_paths = []\n",
        "for root, _, files_ in os.walk(extract_dir):\n",
        "    for f in files_:\n",
        "        if f.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
        "            img_paths.append(os.path.join(root, f))\n",
        "\n",
        "def num_key(p):\n",
        "    stem = os.path.splitext(os.path.basename(p))[0]\n",
        "    m = re.findall(r\"\\d+\", stem)\n",
        "    return int(m[0]) if m else 10**9\n",
        "\n",
        "img_paths.sort(key=num_key)\n",
        "\n",
        "print(\"Found images:\", len(img_paths))\n",
        "if len(img_paths) < SEQ_LEN:\n",
        "    raise ValueError(f\"Need at least {SEQ_LEN} images, but found {len(img_paths)}\")\n",
        "\n",
        "seq_paths = img_paths[:SEQ_LEN]\n",
        "\n",
        "# One-sample dataset\n",
        "dummy_label = 0\n",
        "ds_one = tf.data.Dataset.from_tensor_slices(([seq_paths], [dummy_label]))\n",
        "ds_one = ds_one.map(load_sequence).batch(1)\n",
        "\n",
        "prob = loaded_model.predict(ds_one, verbose=0)[0]\n",
        "pred = int(np.argmax(prob))\n",
        "conf = float(np.max(prob))\n",
        "\n",
        "print(\"\\n=== MANUAL UPLOAD PREDICTION ===\")\n",
        "print(\"Predicted class:\", label_map[pred])\n",
        "print(\"Confidence:\", conf)\n",
        "print(\"Probabilities [NSR, ARR]:\", prob)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "mqFzrqTQW-tg",
        "outputId": "0471b559-0271-430b-dfbb-04c33b370ea2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Upload a ZIP containing 10 scalogram images (e.g., 0.png..9.png).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4c014dc3-fa86-49e2-971f-74bcb67e45b5\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4c014dc3-fa86-49e2-971f-74bcb67e45b5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 234_MLII_segments.zip to 234_MLII_segments.zip\n",
            "Found images: 10\n",
            "\n",
            "=== MANUAL UPLOAD PREDICTION ===\n",
            "Predicted class: ARR\n",
            "Confidence: 0.6437506079673767\n",
            "Probabilities [NSR, ARR]: [0.3562494 0.6437506]\n"
          ]
        }
      ]
    }
  ]
}